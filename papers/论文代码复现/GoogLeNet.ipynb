{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13696\\3847204093.py:70: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of GoogleNet will be changed in future releases of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "       BasicConv2d-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "       BasicConv2d-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8          [-1, 192, 56, 56]         110,592\n",
      "       BatchNorm2d-9          [-1, 192, 56, 56]             384\n",
      "      BasicConv2d-10          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 192, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          12,288\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 96, 28, 28]          18,432\n",
      "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-17           [-1, 96, 28, 28]               0\n",
      "           Conv2d-18          [-1, 128, 28, 28]         110,592\n",
      "      BatchNorm2d-19          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-20          [-1, 128, 28, 28]               0\n",
      "           Conv2d-21           [-1, 16, 28, 28]           3,072\n",
      "      BatchNorm2d-22           [-1, 16, 28, 28]              32\n",
      "      BasicConv2d-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-26           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-27          [-1, 192, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-30           [-1, 32, 28, 28]               0\n",
      "        Inception-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 192, 28, 28]         221,184\n",
      "      BatchNorm2d-39          [-1, 192, 28, 28]             384\n",
      "      BasicConv2d-40          [-1, 192, 28, 28]               0\n",
      "           Conv2d-41           [-1, 32, 28, 28]           8,192\n",
      "      BatchNorm2d-42           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 96, 28, 28]          27,648\n",
      "      BatchNorm2d-45           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-46           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-47          [-1, 256, 28, 28]               0\n",
      "           Conv2d-48           [-1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-49           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-50           [-1, 64, 28, 28]               0\n",
      "        Inception-51          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-52          [-1, 480, 14, 14]               0\n",
      "           Conv2d-53          [-1, 192, 14, 14]          92,160\n",
      "      BatchNorm2d-54          [-1, 192, 14, 14]             384\n",
      "      BasicConv2d-55          [-1, 192, 14, 14]               0\n",
      "           Conv2d-56           [-1, 96, 14, 14]          46,080\n",
      "      BatchNorm2d-57           [-1, 96, 14, 14]             192\n",
      "      BasicConv2d-58           [-1, 96, 14, 14]               0\n",
      "           Conv2d-59          [-1, 208, 14, 14]         179,712\n",
      "      BatchNorm2d-60          [-1, 208, 14, 14]             416\n",
      "      BasicConv2d-61          [-1, 208, 14, 14]               0\n",
      "           Conv2d-62           [-1, 16, 14, 14]           7,680\n",
      "      BatchNorm2d-63           [-1, 16, 14, 14]              32\n",
      "      BasicConv2d-64           [-1, 16, 14, 14]               0\n",
      "           Conv2d-65           [-1, 48, 14, 14]           6,912\n",
      "      BatchNorm2d-66           [-1, 48, 14, 14]              96\n",
      "      BasicConv2d-67           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-68          [-1, 480, 14, 14]               0\n",
      "           Conv2d-69           [-1, 64, 14, 14]          30,720\n",
      "      BatchNorm2d-70           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-71           [-1, 64, 14, 14]               0\n",
      "        Inception-72          [-1, 512, 14, 14]               0\n",
      "           Conv2d-73            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-74            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-75            [-1, 128, 4, 4]               0\n",
      "           Linear-76                 [-1, 1024]       2,098,176\n",
      "           Linear-77                 [-1, 1000]       1,025,000\n",
      "     InceptionAux-78                 [-1, 1000]               0\n",
      "           Conv2d-79          [-1, 160, 14, 14]          81,920\n",
      "      BatchNorm2d-80          [-1, 160, 14, 14]             320\n",
      "      BasicConv2d-81          [-1, 160, 14, 14]               0\n",
      "           Conv2d-82          [-1, 112, 14, 14]          57,344\n",
      "      BatchNorm2d-83          [-1, 112, 14, 14]             224\n",
      "      BasicConv2d-84          [-1, 112, 14, 14]               0\n",
      "           Conv2d-85          [-1, 224, 14, 14]         225,792\n",
      "      BatchNorm2d-86          [-1, 224, 14, 14]             448\n",
      "      BasicConv2d-87          [-1, 224, 14, 14]               0\n",
      "           Conv2d-88           [-1, 24, 14, 14]          12,288\n",
      "      BatchNorm2d-89           [-1, 24, 14, 14]              48\n",
      "      BasicConv2d-90           [-1, 24, 14, 14]               0\n",
      "           Conv2d-91           [-1, 64, 14, 14]          13,824\n",
      "      BatchNorm2d-92           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-93           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-94          [-1, 512, 14, 14]               0\n",
      "           Conv2d-95           [-1, 64, 14, 14]          32,768\n",
      "      BatchNorm2d-96           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-97           [-1, 64, 14, 14]               0\n",
      "        Inception-98          [-1, 512, 14, 14]               0\n",
      "           Conv2d-99          [-1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-101          [-1, 128, 14, 14]               0\n",
      "          Conv2d-102          [-1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-103          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-104          [-1, 128, 14, 14]               0\n",
      "          Conv2d-105          [-1, 256, 14, 14]         294,912\n",
      "     BatchNorm2d-106          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-107          [-1, 256, 14, 14]               0\n",
      "          Conv2d-108           [-1, 24, 14, 14]          12,288\n",
      "     BatchNorm2d-109           [-1, 24, 14, 14]              48\n",
      "     BasicConv2d-110           [-1, 24, 14, 14]               0\n",
      "          Conv2d-111           [-1, 64, 14, 14]          13,824\n",
      "     BatchNorm2d-112           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-113           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-114          [-1, 512, 14, 14]               0\n",
      "          Conv2d-115           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-116           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-117           [-1, 64, 14, 14]               0\n",
      "       Inception-118          [-1, 512, 14, 14]               0\n",
      "          Conv2d-119          [-1, 112, 14, 14]          57,344\n",
      "     BatchNorm2d-120          [-1, 112, 14, 14]             224\n",
      "     BasicConv2d-121          [-1, 112, 14, 14]               0\n",
      "          Conv2d-122          [-1, 144, 14, 14]          73,728\n",
      "     BatchNorm2d-123          [-1, 144, 14, 14]             288\n",
      "     BasicConv2d-124          [-1, 144, 14, 14]               0\n",
      "          Conv2d-125          [-1, 288, 14, 14]         373,248\n",
      "     BatchNorm2d-126          [-1, 288, 14, 14]             576\n",
      "     BasicConv2d-127          [-1, 288, 14, 14]               0\n",
      "          Conv2d-128           [-1, 32, 14, 14]          16,384\n",
      "     BatchNorm2d-129           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-130           [-1, 32, 14, 14]               0\n",
      "          Conv2d-131           [-1, 64, 14, 14]          18,432\n",
      "     BatchNorm2d-132           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-133           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-134          [-1, 512, 14, 14]               0\n",
      "          Conv2d-135           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-136           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-137           [-1, 64, 14, 14]               0\n",
      "       Inception-138          [-1, 528, 14, 14]               0\n",
      "          Conv2d-139            [-1, 128, 4, 4]          67,584\n",
      "     BatchNorm2d-140            [-1, 128, 4, 4]             256\n",
      "     BasicConv2d-141            [-1, 128, 4, 4]               0\n",
      "          Linear-142                 [-1, 1024]       2,098,176\n",
      "          Linear-143                 [-1, 1000]       1,025,000\n",
      "    InceptionAux-144                 [-1, 1000]               0\n",
      "          Conv2d-145          [-1, 256, 14, 14]         135,168\n",
      "     BatchNorm2d-146          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-147          [-1, 256, 14, 14]               0\n",
      "          Conv2d-148          [-1, 160, 14, 14]          84,480\n",
      "     BatchNorm2d-149          [-1, 160, 14, 14]             320\n",
      "     BasicConv2d-150          [-1, 160, 14, 14]               0\n",
      "          Conv2d-151          [-1, 320, 14, 14]         460,800\n",
      "     BatchNorm2d-152          [-1, 320, 14, 14]             640\n",
      "     BasicConv2d-153          [-1, 320, 14, 14]               0\n",
      "          Conv2d-154           [-1, 32, 14, 14]          16,896\n",
      "     BatchNorm2d-155           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-156           [-1, 32, 14, 14]               0\n",
      "          Conv2d-157          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-158          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-159          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-160          [-1, 528, 14, 14]               0\n",
      "          Conv2d-161          [-1, 128, 14, 14]          67,584\n",
      "     BatchNorm2d-162          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-163          [-1, 128, 14, 14]               0\n",
      "       Inception-164          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-165            [-1, 832, 7, 7]               0\n",
      "          Conv2d-166            [-1, 256, 7, 7]         212,992\n",
      "     BatchNorm2d-167            [-1, 256, 7, 7]             512\n",
      "     BasicConv2d-168            [-1, 256, 7, 7]               0\n",
      "          Conv2d-169            [-1, 160, 7, 7]         133,120\n",
      "     BatchNorm2d-170            [-1, 160, 7, 7]             320\n",
      "     BasicConv2d-171            [-1, 160, 7, 7]               0\n",
      "          Conv2d-172            [-1, 320, 7, 7]         460,800\n",
      "     BatchNorm2d-173            [-1, 320, 7, 7]             640\n",
      "     BasicConv2d-174            [-1, 320, 7, 7]               0\n",
      "          Conv2d-175             [-1, 32, 7, 7]          26,624\n",
      "     BatchNorm2d-176             [-1, 32, 7, 7]              64\n",
      "     BasicConv2d-177             [-1, 32, 7, 7]               0\n",
      "          Conv2d-178            [-1, 128, 7, 7]          36,864\n",
      "     BatchNorm2d-179            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-180            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-181            [-1, 832, 7, 7]               0\n",
      "          Conv2d-182            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-183            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-184            [-1, 128, 7, 7]               0\n",
      "       Inception-185            [-1, 832, 7, 7]               0\n",
      "          Conv2d-186            [-1, 384, 7, 7]         319,488\n",
      "     BatchNorm2d-187            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-188            [-1, 384, 7, 7]               0\n",
      "          Conv2d-189            [-1, 192, 7, 7]         159,744\n",
      "     BatchNorm2d-190            [-1, 192, 7, 7]             384\n",
      "     BasicConv2d-191            [-1, 192, 7, 7]               0\n",
      "          Conv2d-192            [-1, 384, 7, 7]         663,552\n",
      "     BatchNorm2d-193            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-194            [-1, 384, 7, 7]               0\n",
      "          Conv2d-195             [-1, 48, 7, 7]          39,936\n",
      "     BatchNorm2d-196             [-1, 48, 7, 7]              96\n",
      "     BasicConv2d-197             [-1, 48, 7, 7]               0\n",
      "          Conv2d-198            [-1, 128, 7, 7]          55,296\n",
      "     BatchNorm2d-199            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-200            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-201            [-1, 832, 7, 7]               0\n",
      "          Conv2d-202            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-203            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-204            [-1, 128, 7, 7]               0\n",
      "       Inception-205           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-206           [-1, 1024, 1, 1]               0\n",
      "         Dropout-207                 [-1, 1024]               0\n",
      "          Linear-208                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 13,004,888\n",
      "Trainable params: 13,004,888\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 94.25\n",
      "Params size (MB): 49.61\n",
      "Estimated Total Size (MB): 144.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.jit.annotations import Optional, Tuple\n",
    "from torch import Tensor\n",
    "# from .utils import load_state_dict_from_url\n",
    "\n",
    "__all__ = ['GoogLeNet', 'googlenet', \"GoogLeNetOutputs\", \"_GoogLeNetOutputs\"]\n",
    "\n",
    "model_urls = {\n",
    "    # GoogLeNet ported from TensorFlow\n",
    "    'googlenet': 'https://download.pytorch.org/models/googlenet-1378be20.pth',\n",
    "}\n",
    "\n",
    "GoogLeNetOutputs = namedtuple('GoogLeNetOutputs', ['logits', 'aux_logits2', 'aux_logits1'])\n",
    "GoogLeNetOutputs.__annotations__ = {'logits': Tensor, 'aux_logits2': Optional[Tensor],\n",
    "                                    'aux_logits1': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _GoogLeNetOutputs set here for backwards compat\n",
    "_GoogLeNetOutputs = GoogLeNetOutputs\n",
    "\n",
    "\n",
    "def googlenet(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"GoogLeNet (Inception v1) model architecture from\n",
    "    `\"Going Deeper with Convolutions\" <http://arxiv.org/abs/1409.4842>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, adds two auxiliary branches that can improve training.\n",
    "            Default: *False* when pretrained is True otherwise *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' not in kwargs:\n",
    "            kwargs['aux_logits'] = False\n",
    "        if kwargs['aux_logits']:\n",
    "            warnings.warn('auxiliary heads in the pretrained googlenet model are NOT pretrained, '\n",
    "                          'so make sure to train them')\n",
    "        original_aux_logits = kwargs['aux_logits']\n",
    "        kwargs['aux_logits'] = True\n",
    "        kwargs['init_weights'] = False\n",
    "        model = GoogLeNet(**kwargs)\n",
    "        # state_dict = load_state_dict_from_url(model_urls['googlenet'],\n",
    "        #                                       progress=progress)\n",
    "        # model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.aux1 = None\n",
    "            model.aux2 = None\n",
    "        return model\n",
    "\n",
    "    return GoogLeNet(**kwargs)\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    __constants__ = ['aux_logits', 'transform_input']\n",
    "\n",
    "    def __init__(self, num_classes=1000, aux_logits=True, transform_input=False, init_weights=None,\n",
    "                 blocks=None):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        if blocks is None:\n",
    "            blocks = [BasicConv2d, Inception, InceptionAux]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of GoogleNet will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(blocks) == 3\n",
    "        conv_block = blocks[0]\n",
    "        inception_block = blocks[1]\n",
    "        inception_aux_block = blocks[2]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        self.conv2 = conv_block(64, 64, kernel_size=1)\n",
    "        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if aux_logits:\n",
    "            self.aux1 = inception_aux_block(512, num_classes)\n",
    "            self.aux2 = inception_aux_block(528, num_classes)\n",
    "        else:\n",
    "            self.aux1 = None\n",
    "            self.aux2 = None\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                import scipy.stats as stats\n",
    "                X = stats.truncnorm(-2, 2, scale=0.01)\n",
    "                values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n",
    "                values = values.view(m.weight.size())\n",
    "                with torch.no_grad():\n",
    "                    m.weight.copy_(values)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # type: (Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]\n",
    "        # N x 3 x 224 x 224\n",
    "        x = self.conv1(x)\n",
    "        # N x 64 x 112 x 112\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 56 x 56\n",
    "        x = self.conv2(x)\n",
    "        # N x 64 x 56 x 56\n",
    "        x = self.conv3(x)\n",
    "        # N x 192 x 56 x 56\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # N x 192 x 28 x 28\n",
    "        x = self.inception3a(x)\n",
    "        # N x 256 x 28 x 28\n",
    "        x = self.inception3b(x)\n",
    "        # N x 480 x 28 x 28\n",
    "        x = self.maxpool3(x)\n",
    "        # N x 480 x 14 x 14\n",
    "        x = self.inception4a(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        aux1 = torch.jit.annotate(Optional[Tensor], None)\n",
    "        if self.aux1 is not None:\n",
    "            if self.training:\n",
    "                aux1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception4b(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        x = self.inception4c(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        x = self.inception4d(x)\n",
    "        # N x 528 x 14 x 14\n",
    "        aux2 = torch.jit.annotate(Optional[Tensor], None)\n",
    "        if self.aux2 is not None:\n",
    "            if self.training:\n",
    "                aux2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception4e(x)\n",
    "        # N x 832 x 14 x 14\n",
    "        x = self.maxpool4(x)\n",
    "        # N x 832 x 7 x 7\n",
    "        x = self.inception5a(x)\n",
    "        # N x 832 x 7 x 7\n",
    "        x = self.inception5b(x)\n",
    "        # N x 1024 x 7 x 7\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # N x 1024 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 1024\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux2, aux1\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x, aux2, aux1):\n",
    "        # type: (Tensor, Optional[Tensor], Optional[Tensor]) -> GoogLeNetOutputs\n",
    "        if self.training and self.aux_logits:\n",
    "            return _GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # type: (Tensor) -> GoogLeNetOutputs\n",
    "        x = self._transform_input(x)\n",
    "        x, aux1, aux2 = self._forward(x)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted GoogleNet always returns GoogleNetOutputs Tuple\")\n",
    "            return GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux2, aux1)\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj,\n",
    "                 conv_block=None):\n",
    "        super(Inception, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, ch3x3red, kernel_size=1),\n",
    "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
    "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
    "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
    "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            conv_block(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, conv_block=None):\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
    "        x = F.adaptive_avg_pool2d(x, (4, 4))\n",
    "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
    "        x = self.conv(x)\n",
    "        # N x 128 x 4 x 4\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 2048\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        # N x 1024\n",
    "        x = F.dropout(x, 0.7, training=self.training)\n",
    "        # N x 1024\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "from torchsummary import summary  \n",
    "googlenet1 = googlenet()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    googlenet1.cuda()\n",
    "summary(model=googlenet1, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4442a059423b1d8cb2d566f1d7a9e596fd1852f4b9b9e9d6f69b72f942b31330"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
